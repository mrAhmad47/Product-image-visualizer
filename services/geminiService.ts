import { GoogleGenAI } from "@google/genai";

const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
const MODEL_NAME = 'gemini-2.5-flash-image';

export interface GeneratedImageResult {
  imageUrl: string;
  promptUsed: string;
}

/**
 * Generates an edited image or a new variation based on an input image and a text prompt.
 * Uses Gemini 2.5 Flash Image.
 */
export const generateImageEdit = async (
  base64Image: string,
  mimeType: string,
  prompt: string
): Promise<GeneratedImageResult> => {
  try {
    // Strip the data URL prefix if present (e.g., "data:image/png;base64,")
    const base64Data = base64Image.split(',')[1] || base64Image;

    const response = await ai.models.generateContent({
      model: MODEL_NAME,
      contents: {
        parts: [
          {
            text: prompt,
          },
          {
            inlineData: {
              mimeType: mimeType,
              data: base64Data,
            },
          },
        ],
      },
      // Note: responseMimeType and responseSchema are NOT supported for nano banana models
      // Config options for images if needed in future:
      // config: { imageConfig: { aspectRatio: '1:1' } } 
    });

    let generatedImageUrl = '';

    // Iterate through parts to find the image
    if (response.candidates && response.candidates[0].content.parts) {
      for (const part of response.candidates[0].content.parts) {
        if (part.inlineData) {
          const b64 = part.inlineData.data;
          // Assume PNG return or check mimeType if provided by API, usually standard for generated images
          generatedImageUrl = `data:image/png;base64,${b64}`;
          break;
        }
      }
    }

    if (!generatedImageUrl) {
      throw new Error("No image generated by the model.");
    }

    return {
      imageUrl: generatedImageUrl,
      promptUsed: prompt,
    };

  } catch (error) {
    console.error("Error generating image:", error);
    throw error;
  }
};